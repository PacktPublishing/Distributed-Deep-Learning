{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiton "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Transfer Learning**](https://en.wikipedia.org/wiki/Transfer_learning): Transfer learning or inductive transfer is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited. \n",
    "\n",
    "https://en.wikipedia.org/wiki/Transfer_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using **pre-trained CNN features**\n",
    "2. Learning **domain-invariant representations**\n",
    "3. Making representations more similar\n",
    "4. Confusing domains\n",
    "\n",
    "http://ruder.io/transfer-learning/index.html#adaptingtonewdomains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Learning from _simulations_\n",
    "*  Adapting to _new_ _domains_\n",
    "*  Transferring knowledge across _new_ _languages_\n",
    "\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "http://ruder.io/transfer-learning/index.html#adaptingtonewdomains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hf/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential,Model \n",
    "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense , BatchNormalization \n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image \n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint ,EarlyStopping \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.applications.xception import preprocess_input\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 2\n",
    "img_width, img_height = 256, 256\n",
    "n_train_samples = 6000\n",
    "n_validation_samples = 1000\n",
    "n_test_samples = 200\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "test_data_dir = 'data/test'\n",
    "top_model_weights_path = 'cat_dog_Xception.h5'\n",
    "\n",
    "based_model_last_block_layer_number = 126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data/train**\n",
    " \n",
    " \n",
    " cat/\n",
    " \n",
    " dog/\n",
    " \n",
    " \n",
    "**data/validation**\n",
    "  \n",
    "  \n",
    "  cat/\n",
    "  \n",
    "  dog/\n",
    "  \n",
    "  \n",
    "  **data/test**\n",
    "  \n",
    "  \n",
    "  cat/\n",
    "  \n",
    "  dog/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image \n",
    "import PIL\n",
    "plt.figure(figsize =(10,10))\n",
    "images = range(0,9)\n",
    "for i in images:\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(image.load_img('data/train/cat/cat.'+str(i) +'.jpg', target_size = (150,150)),\n",
    "               cmap=plt.get_cmap('gray'))\n",
    "    plt.xlabel('cat '+str(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,10))\n",
    "images = range(0,9)\n",
    "for i in images:\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(image.load_img('data/train/dog/dog.'+str(9000+i) +'.jpg', target_size = (150,150)),\n",
    "               cmap=plt.get_cmap('gray'))\n",
    "    plt.xlabel('dog '+str(i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "img = load_img('data/train/cat/cat.0.jpg') \n",
    "x = img_to_array(img)  \n",
    "x = x.reshape((1,) + x.shape)  \n",
    "\n",
    "i = 0\n",
    "for batch in train_datagen.flow(x, batch_size=1,save_to_dir='data/aug_images', \n",
    "                          save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](collage.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Xception Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras.applications.xception.Xception(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xception V1 model, with weights pre-trained on ImageNet.**\n",
    "\n",
    "\n",
    "**include_top:** whether to include the fully-connected layer at the top of the network.\n",
    "\n",
    "\n",
    "**weights:** one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n",
    "\n",
    "\n",
    "**input_tensor:** optional Keras tensor (i.e. output of  layers.Input()) to use as image input for the model.\n",
    "\n",
    "\n",
    "**input_shape:** optional shape tuple, only to be specified if  include_top is False (otherwise the input shape has to be  (224, 224, 3) (with 'channels_last' data format) or  (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 197. E.g. (200, 200, 3) would be one valid value.\n",
    "\n",
    "\n",
    "**pooling:** Optional pooling mode for feature extraction when  include_top is False.\n",
    "None means that the output of the model will be the 4D tensor output of the last convolutional layer.\n",
    "'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor.\n",
    "'max' means that global max pooling will be applied.\n",
    "\n",
    "\n",
    "**classes:** optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a Keras Model instance. Read more: https://keras.io/applications/#xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xception Network:**\n",
    "\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1610.02357.pdf\n",
    "\n",
    "\n",
    "Github: https://github.com/fchollet/deep-learning-models/blob/master/xception.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](xception.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = applications.xception.Xception(include_top = False,\n",
    "                                     weights ='imagenet',\n",
    "                                     input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation ='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "y_pred = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_final = Model(inputs=model.input, outputs= y_pred)\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze the layers that you are going to retrain\n",
    "Here we freeze the rest layers except the layers in the last block of Xception network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model.layers[:based_model_last_block_layer_number]:\n",
    "    layers.trainable= False\n",
    "for layer in model.layers[based_model_last_block_layer_number:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **.flow_from_directory()** to generate batches of image data (and their labels) directly from our .jpgs in their respective directories.\n",
    "\n",
    "**flow_from_directory(directory)**: Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "More details: https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                       target_size = (img_width, img_height),\n",
    "                                       batch_size = batch_size,\n",
    "                                       class_mode =  \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                        validation_data_dir,\n",
    "                                        target_size= (img_width, img_height),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode= \"categorical\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                target_size= (img_width, img_height),\n",
    "                                batch_size=batch_size,\n",
    "                                class_mode= \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "**\n",
    "\n",
    "\n",
    "Nesterov Adam optimizer.\n",
    "\n",
    "Much like Adam is essentially RMSprop with momentum, Nadam is Adam RMSprop with Nesterov momentum.\n",
    "\n",
    "To learn more: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save the Model\n",
    "Now, we can use these generator to train our model. with **model.fit_generator()**.\n",
    "\n",
    "\n",
    "Save the model with **keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1** which will save the model after every epoch.\n",
    "\n",
    "Learn More: https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_training(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath = top_model_weights_path,\n",
    "                            verbose = 1,\n",
    "                            save_best_only = True,\n",
    "                            monitor = 'val_acc')\n",
    "early = EarlyStopping(monitor='val_acc', min_delta = 0, patience =5,verbose=1, mode ='auto')\n",
    "\n",
    "history = model_final.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = n_train_samples // batch_size,\n",
    "        epochs= epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps = n_validation_samples // batch_size,\n",
    "        callbacks = [checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)**\n",
    "\n",
    "\n",
    "Evaluates the model on a data generator.\n",
    "\n",
    "The generator should return the same kind of data as accepted by test_on_batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, acc = model_final.evaluate_generator(test_generator, steps =n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.2f%%' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)**\n",
    "\n",
    "\n",
    "Generates predictions for the input samples from a data generator.\n",
    "\n",
    "The generator should return Numpy array(s) of predictions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = model_final.predict_generator(test_generator, steps= n_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('andy.jpg')\n",
    "target_size = (256,256)\n",
    "\n",
    "if img.size != target_size:\n",
    "    img = img.resize(target_size)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model_final.predict(x)\n",
    "print('Probabilities for dog and cat:', preds[0])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "labels = (\"dog\",\"cat\")\n",
    "plt.barh([0, 1], preds[0], alpha=0.5)\n",
    "plt.yticks([0, 1], labels)\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0,1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = image.load_img('zao.jpg')\n",
    "target_size = (256,256)\n",
    "\n",
    "if img.size != target_size:\n",
    "    img = img.resize(target_size)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model_final.predict(x)\n",
    "print('Probabilities for cat and dog:', preds[0])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure()\n",
    "labels = ('cat','dog')\n",
    "plt.barh([0, 1], preds[0], alpha=0.5)\n",
    "plt.yticks([0, 1], labels)\n",
    "plt.xlabel('Probability')\n",
    "plt.xlim(0,1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve the result, you can try to 'fine-tune\" the last convolutional block of the Xception network alongside the top-level classifier. \n",
    "\n",
    "**Fine-tuning** consist of starting from a trained network, then re-train it on a new dataset using a very small weight updates (small learning rate). In our case, this can be done in 3 stpes: \n",
    "\n",
    "1. Instantiate the convolutional base of Xception and load the weights;\n",
    "2. Add our previous defined fully-connected model on top and load its weights;\n",
    "3. Freeze the layers on the Xception model up to the last convolutional block.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Github Link: https://github.com/haohan723/Distributed-Deep-Learning/blob/master/Keras%20Introduction/Training_with_Augmentation_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
